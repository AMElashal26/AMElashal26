{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AMElashal26/AMElashal26/blob/main/Python_Reddit_Scraper_S.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reddit_scraper.py\n",
        "#\n",
        "# Description:\n",
        "# This script uses the Python Reddit API Wrapper (PRAW) to scrape posts and\n",
        "# comments from a specified subreddit and saves them to a text file.\n",
        "#\n",
        "# Prerequisites:\n",
        "# 1. Python 3.6+\n",
        "# 2. PRAW library: Install it using pip -> pip install praw\n",
        "# 3. A Reddit account.\n",
        "#\n",
        "# How to get Reddit API Credentials:\n",
        "# 1. Go to https://www.reddit.com/prefs/apps\n",
        "# 2. Log in with your Reddit account.\n",
        "# 3. Scroll to the bottom and click \"are you a developer? create an app...\"\n",
        "# 4. Fill out the form:\n",
        "#    - name: Give your script a unique name (e.g., my_python_scraper_v1)\n",
        "#    - type: Select \"script\"\n",
        "#    - description: (Optional) A brief description.\n",
        "#    - about url: (Optional)\n",
        "#    - redirect uri: http://localhost:8080 (This is required for script apps)\n",
        "# 5. Click \"create app\".\n",
        "# 6. You will now see your app's credentials.\n",
        "#    - The string of characters under your app name is the \"client_id\".\n",
        "#    - The string labeled \"secret\" is the \"client_secret\".\n",
        "# 7. Copy these values into the script below.\n",
        "\n",
        "import praw\n",
        "import argparse\n",
        "import sys\n",
        "from datetime import datetime\n",
        "\n",
        "def scrape_reddit(subreddit_name, post_limit, comment_limit):\n",
        "    \"\"\"\n",
        "    Scrapes a subreddit for a given number of posts and comments.\n",
        "\n",
        "    Args:\n",
        "        subreddit_name (str): The name of the subreddit to scrape.\n",
        "        post_limit (int): The maximum number of posts to fetch.\n",
        "        comment_limit (int): The maximum number of comments to fetch per post.\n",
        "    \"\"\"\n",
        "    print(\"Starting the Reddit scraper...\")\n",
        "\n",
        "    # --- IMPORTANT: PASTE YOUR REDDIT API CREDENTIALS HERE ---\n",
        "    try:\n",
        "        reddit = praw.Reddit(\n",
        "            client_id=\"YOUR_CLIENT_ID\", # Replace with your client ID\n",
        "            client_secret=\"YOUR_CLIENT_SECRET\", # Replace with your client secret\n",
        "            user_agent=\"MyScraper/1.0 by u/YourUsername\", # Replace with your app name and Reddit username\n",
        "        )\n",
        "        # Verify that the connection is read-only and successful\n",
        "        print(f\"API Connection Read-Only: {reddit.read_only}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error connecting to Reddit API: {e}\")\n",
        "        print(\"Please ensure your client_id, client_secret, and user_agent are correct.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Get the subreddit instance\n",
        "        subreddit = reddit.subreddit(subreddit_name)\n",
        "        # Check if the subreddit exists\n",
        "        subreddit.hot(limit=1)\n",
        "        print(f\"Successfully connected to r/{subreddit_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: Could not access subreddit 'r/{subreddit_name}'.\")\n",
        "        print(f\"Please check if the subreddit name is correct and public. Details: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Define the output filename\n",
        "    filename = f\"{subreddit_name}_posts_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
        "\n",
        "    print(f\"Fetching {post_limit} hot posts from r/{subreddit_name}...\")\n",
        "\n",
        "    # Open the file to write the scraped data\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(f\"--- Scraped Data from r/{subreddit_name} on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ---\\n\\n\")\n",
        "\n",
        "        post_count = 0\n",
        "        # Fetch the 'hot' posts from the subreddit\n",
        "        for post in subreddit.hot(limit=post_limit):\n",
        "            post_count += 1\n",
        "            # Write post details to the file\n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "            f.write(f\"POST #{post_count}: {post.title}\\n\")\n",
        "            f.write(f\"URL: https://www.reddit.com{post.permalink}\\n\")\n",
        "            f.write(f\"SCORE: {post.score}\\n\")\n",
        "            f.write(f\"AUTHOR: u/{post.author}\\n\")\n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "\n",
        "            # Write the post's main content (selftext) if it exists\n",
        "            if post.selftext:\n",
        "                f.write(\"POST CONTENT:\\n\")\n",
        "                f.write(post.selftext + \"\\n\")\n",
        "                f.write(\"-\"*80 + \"\\n\")\n",
        "\n",
        "            f.write(f\"TOP {comment_limit} COMMENTS:\\n\\n\")\n",
        "\n",
        "            # Fetch the comments for the post\n",
        "            # 'submission.comments.replace_more(limit=0)' removes \"load more comments\" links\n",
        "            post.comments.replace_more(limit=0)\n",
        "            comment_count = 0\n",
        "            for comment in post.comments.list():\n",
        "                if comment_count >= comment_limit:\n",
        "                    break\n",
        "                if not comment.stickied: # Ignore stickied/moderator comments\n",
        "                    f.write(f\"  Comment #{comment_count + 1} | Score: {comment.score} | Author: u/{comment.author}\\n\")\n",
        "                    # Replace newlines in comment body to keep formatting clean\n",
        "                    comment_body = comment.body.replace('\\n', '\\n  ')\n",
        "                    f.write(f\"  > {comment_body}\\n\\n\")\n",
        "                    comment_count += 1\n",
        "\n",
        "            f.write(\"\\n\\n\") # Add space before the next post\n",
        "            print(f\"  > Processed Post #{post_count}: '{post.title[:50]}...'\")\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"Scraping complete!\")\n",
        "    print(f\"Data for {post_count} posts saved to '{filename}'\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set up command-line argument parsing\n",
        "    parser = argparse.ArgumentParser(description=\"Scrape posts and comments from a subreddit.\")\n",
        "    parser.add_argument(\"subreddit\", help=\"The name of the subreddit to scrape (e.g., 'python').\")\n",
        "    parser.add_argument(\"-p\", \"--posts\", type=int, default=10, help=\"The number of posts to scrape (default: 10).\")\n",
        "    parser.add_argument(\"-c\", \"--comments\", type=int, default=5, help=\"The number of comments to scrape per post (default: 5).\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Run the scraper function with the provided arguments\n",
        "    scrape_reddit(args.subreddit, args.posts, args.comments)\n",
        "\n",
        "# --- How to Run the Script ---\n",
        "# 1. Save this file as \"reddit_scraper.py\".\n",
        "# 2. Open your terminal or command prompt.\n",
        "# 3. Navigate to the directory where you saved the file.\n",
        "# 4. Run the script using a command like this:\n",
        "#\n",
        "#    python reddit_scraper.py python -p 25 -c 10\n",
        "#\n",
        "#    - \"python\" is the subreddit name.\n",
        "#    - \"-p 25\" sets the post limit to 25.\n",
        "#    - \"-c 10\" sets the comment limit to 10 per post.\n",
        "#\n",
        "# 5. A .txt file will be created in the same directory."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "0zqEpHxktHFy"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}